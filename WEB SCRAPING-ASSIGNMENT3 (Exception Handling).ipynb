{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459e0ece",
   "metadata": {},
   "source": [
    "# 1. Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed12ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25846397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yogendra\\AppData\\Local\\Temp\\ipykernel_124096\\2802906935.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2057afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06c9f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_field_designation.send_keys(\"guitars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2998d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8279d34c",
   "metadata": {},
   "source": [
    "# 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36fa91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls=[]\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "    for i in url:\n",
    "        product_urls.append(i.get_attribute(\"href\"))\n",
    "    nxt_button=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "    nxt_button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1abfcd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87479a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        Brand.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_name=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        product_name=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        product.append(product_name.text)\n",
    "    except NoSuchElementException:\n",
    "        product.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_rs=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        price_rs=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        price.append(price_rs.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_exchange=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        return_exchange=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        exchange.append(return_exchange.text)\n",
    "    except NoSuchElementException:\n",
    "        exchange.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_del=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        expected_del=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        delivery.append(expected_del.text)\n",
    "    except NoSuchElementException:\n",
    "        delivery.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Avail_ability=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        avail_ability=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        avail.append(avail_ability.text)\n",
    "    except NoSuchElementException:\n",
    "        avail.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b2355",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_URL=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        product_url=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        url.append(product_url.text)\n",
    "    except NoSuchElementException:\n",
    "        url.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cd16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eddfd5d",
   "metadata": {},
   "source": [
    "# 3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4bf9f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yogendra\\AppData\\Local\\Temp\\ipykernel_9632\\2802906935.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e2c56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://images.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa06b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element(By.XPATH,\"//html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea\")\n",
    "search_field_designation.send_keys(\"cakes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28fe54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/button/div/span\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "045ba486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n",
      "Downloading 10 of 10 images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'breakBy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img_urls)):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m         \u001b[43mbreakBy\u001b[49m\u001b[38;5;241m.\u001b[39mXPATH,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m.\u001b[39mformat(i,\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m     16\u001b[0m     response\u001b[38;5;241m=\u001b[39mrequests\u001b[38;5;241m.\u001b[39mget(img_urls[i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'breakBy' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "images = driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "img_urls=[]\n",
    "img_data=[]\n",
    "for image in images:\n",
    "    source=image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4]=='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i>10:\n",
    "        breakBy.XPATH,\n",
    "    print(\"Downloading {0} of {1} images\" .format(i,10))\n",
    "    response=requests.get(img_urls[i])\n",
    "    file=open(r\"F:\\FLIP LOBO internship\"+str(i)+\".jpg\",\"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693af71d",
   "metadata": {},
   "source": [
    "# 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_field_designation.send_keys(\"smartphone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faddb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ce9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls=[]\n",
    "start = 0\n",
    "end = 1\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "    for i in url:\n",
    "        product_urls.append(i.get_attribute(\"href\"))\n",
    "    nxt_button=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "    nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558101a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        Brand.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smartphone=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        smartphone=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        smartphone.append(smartphone.text)\n",
    "    except NoSuchElementException:\n",
    "        smartphone.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf62f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        Brand.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298fda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49bd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e58aa2",
   "metadata": {},
   "source": [
    "# 5. Write a program to scrape geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e170095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yogendra\\AppData\\Local\\Temp\\ipykernel_9632\\2802906935.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a238940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.google.com/maps/place/Noida,+Uttar+Pradesh/@28.522404,77.2370094,11z/data=!3m1!4b1!4m6!3m5!1s0x390ce5a43173357b:0x37ffce30c87cc03f!8m2!3d28.5355161!4d77.3910265!16zL20vMDN3dHow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1426cde3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (720768147.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [29]\u001b[1;36m\u001b[0m\n\u001b[1;33m    lat_lng=re.findall(r'@(.*)data',url_string)\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    url_string=driver.current_url\n",
    "    print(\"URL Extracted: \",url_string)\n",
    "    lat_lng=re.findall(r'@(.*)data',url_string)\n",
    "\n",
    "#then use split function to split lat lng and will use indexinf to find lat and long separetely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"welcome to the jungle\"\n",
    "\n",
    "x = txt.split()\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06bc2a",
   "metadata": {},
   "source": [
    "# 6. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0bd896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yogendra\\AppData\\Local\\Temp\\ipykernel_9632\\2802906935.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56739f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.digit.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00fe68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,\"/html/body/div[7]/div/div[2]/div[2]/div[3]/ul/li[9]/a\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57586379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538bf05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "993e55b7",
   "metadata": {},
   "source": [
    "# 7. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5324cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa892bd2",
   "metadata": {},
   "source": [
    "# 8. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03389c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#1000 time we scroll down by 10000 in order to generate more comments\n",
    "for _ in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a67b35",
   "metadata": {},
   "source": [
    "# 9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7368ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:Users\\HP\\Desktop\\Fliprobo notes\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c192e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.hostelworld.com/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
