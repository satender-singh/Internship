{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a94d81f",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15c436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (4.8.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\yogendra\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9affbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c763a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da2a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771736c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data.Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc25c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d99595",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64d9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2154d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a13a8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48d5b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0121a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "192bd111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39708a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analysis &amp; Interpretation Technology OpS ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analysis &amp; Interpretation Application Dev...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reference Data Analyst - Trade and Settlement</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer/Data Analyst</td>\n",
       "      <td>Hybrid - Kolkata, Hyderabad/Secunderabad, Pune...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst || Bangalore || Male/ Female || 1...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Permanent Remote</td>\n",
       "      <td>Tvaksa Technologies</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Startup Scalers</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Qualitest</td>\n",
       "      <td>10-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Procurement Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Data Analysis & Interpretation Technology OpS ...   \n",
       "1  Data Analysis & Interpretation Application Dev...   \n",
       "2      Reference Data Analyst - Trade and Settlement   \n",
       "3                         Data Engineer/Data Analyst   \n",
       "4  Data Analyst || Bangalore || Male/ Female || 1...   \n",
       "5                                       Data Analyst   \n",
       "6                                   Sr. Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                           Procurement Data Analyst   \n",
       "\n",
       "                                            Location         Company_Name  \\\n",
       "0                                Bangalore/Bengaluru            Accenture   \n",
       "1                                Bangalore/Bengaluru            Accenture   \n",
       "2                       Hybrid - Bangalore/Bengaluru        Deutsche Bank   \n",
       "3  Hybrid - Kolkata, Hyderabad/Secunderabad, Pune...        Tech Mahindra   \n",
       "4                                Bangalore/Bengaluru            TeamLease   \n",
       "5                                   Permanent Remote  Tvaksa Technologies   \n",
       "6                                Bangalore/Bengaluru      Startup Scalers   \n",
       "7                                Bangalore/Bengaluru                  ANZ   \n",
       "8                                Bangalore/Bengaluru            Qualitest   \n",
       "9                                Bangalore/Bengaluru   Schneider Electric   \n",
       "\n",
       "  experience  \n",
       "0    4-6 Yrs  \n",
       "1    4-6 Yrs  \n",
       "2    1-6 Yrs  \n",
       "3   6-11 Yrs  \n",
       "4    1-5 Yrs  \n",
       "5   7-12 Yrs  \n",
       "6  10-15 Yrs  \n",
       "7    5-8 Yrs  \n",
       "8  10-20 Yrs  \n",
       "9    2-3 Yrs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Title\":job_title,\"Location\":job_location,\"Company_Name\":company_name,\"experience\":experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6267510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d87c24",
   "metadata": {},
   "source": [
    "# Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4141c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dda6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce117525",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data.Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02b03cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"//html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb0a1d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9573b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "264e03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66577143",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37a4fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1581e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b29e156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Brainlabs Digital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Transunion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Permanent Remote</td>\n",
       "      <td>TEG Business Solutions Pvt Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Manager - Data Scientist - Chubb-Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Chubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Slice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist-Analytics</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>Gcc Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>NOVAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Senior Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Piramal Capital &amp; Housing Finance (PCHFL)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0                              Data Scientist   \n",
       "1                       SENIOR DATA SCIENTIST   \n",
       "2                       SENIOR DATA SCIENTIST   \n",
       "3                       Senior Data Scientist   \n",
       "4                         Lead Data Scientist   \n",
       "5  Manager - Data Scientist - Chubb-Bangalore   \n",
       "6                              Data Scientist   \n",
       "7                    Data Scientist-Analytics   \n",
       "8                              Data Scientist   \n",
       "9             Data Scientist - Senior Manager   \n",
       "\n",
       "                                  Location  \\\n",
       "0                      Bangalore/Bengaluru   \n",
       "1                      Bangalore/Bengaluru   \n",
       "2                      Bangalore/Bengaluru   \n",
       "3                Pune, Bangalore/Bengaluru   \n",
       "4                         Permanent Remote   \n",
       "5                      Bangalore/Bengaluru   \n",
       "6                      Bangalore/Bengaluru   \n",
       "7             Hybrid - Bangalore/Bengaluru   \n",
       "8             Chennai, Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "\n",
       "                                Company_Name  \n",
       "0                          Brainlabs Digital  \n",
       "1                                    Walmart  \n",
       "2                                    Walmart  \n",
       "3                                 Transunion  \n",
       "4             TEG Business Solutions Pvt Ltd  \n",
       "5                                      Chubb  \n",
       "6                                      Slice  \n",
       "7                               Gcc Services  \n",
       "8                                      NOVAC  \n",
       "9  Piramal Capital & Housing Finance (PCHFL)  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Title\":job_title,\"Location\":job_location,\"Company_Name\":company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ec2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3dfdde",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7d542ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9395a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e1a9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data.Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4c1410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a246ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_delhi=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[4]/div[2]/div[3]/label/p/span[1]\")\n",
    "location_delhi.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52fe4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_delhi=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary_delhi.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a61a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_job=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f3b289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35d7887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8b6fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b054d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_job.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "763b288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5568a036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Academic Counsellor - Inside Sales | CTC UpTo ...</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Datatrained</td>\n",
       "      <td>Datatrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Delhi / NCR, Kochi/Cochin, Noida, Kol...</td>\n",
       "      <td>Ezeiatech Systems Pvt. Ltd.</td>\n",
       "      <td>Ezeiatech Systems Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aws Data Engineer</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Cognizant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For freshers - AR Caller (NTT Data)</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Editor</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Data Bridge (DBMR)</td>\n",
       "      <td>Data Bridge (DBMR)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NMS Consultant</td>\n",
       "      <td>NMS Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Freshers Walk-In For Premium Sales Process | F...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Datatrained</td>\n",
       "      <td>Datatrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring Freshers For Sales Process - Mega BPO H...</td>\n",
       "      <td>Noida, Greater Noida</td>\n",
       "      <td>Datatrained</td>\n",
       "      <td>Datatrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Walk-In For Inside Sales | Fixed Day Shift - D...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Data Trained Education Pvt. Ltd.</td>\n",
       "      <td>Data Trained Education Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Academic Counsellor - Inside Sales | CTC UpTo ...   \n",
       "1                              Junior Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                                  Aws Data Engineer   \n",
       "4         Hiring For freshers - AR Caller (NTT Data)   \n",
       "5                                             Editor   \n",
       "6                                     Data Scientist   \n",
       "7  Freshers Walk-In For Premium Sales Process | F...   \n",
       "8  Hiring Freshers For Sales Process - Mega BPO H...   \n",
       "9  Walk-In For Inside Sales | Fixed Day Shift - D...   \n",
       "\n",
       "                                            Location  \\\n",
       "0    Gurgaon/Gurugram, United States (USA), Bulgaria   \n",
       "1                                   Gurgaon/Gurugram   \n",
       "2  Hybrid - Delhi / NCR, Kochi/Cochin, Noida, Kol...   \n",
       "3                                              Noida   \n",
       "4                 Noida, New Delhi, Gurgaon/Gurugram   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6                                              Noida   \n",
       "7                                              Noida   \n",
       "8                               Noida, Greater Noida   \n",
       "9                                              Noida   \n",
       "\n",
       "                                  Company_Name  \\\n",
       "0                                  Datatrained   \n",
       "1                                       Adidas   \n",
       "2                  Ezeiatech Systems Pvt. Ltd.   \n",
       "3                                    Cognizant   \n",
       "4  NTT DATA Business Solutions Private Limited   \n",
       "5                           Data Bridge (DBMR)   \n",
       "6                               NMS Consultant   \n",
       "7                                  Datatrained   \n",
       "8                                  Datatrained   \n",
       "9             Data Trained Education Pvt. Ltd.   \n",
       "\n",
       "                                    Experience  \n",
       "0                                  Datatrained  \n",
       "1                                       Adidas  \n",
       "2                  Ezeiatech Systems Pvt. Ltd.  \n",
       "3                                    Cognizant  \n",
       "4  NTT DATA Business Solutions Private Limited  \n",
       "5                           Data Bridge (DBMR)  \n",
       "6                               NMS Consultant  \n",
       "7                                  Datatrained  \n",
       "8                                  Datatrained  \n",
       "9             Data Trained Education Pvt. Ltd.  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Title\":job_title,\"Location\":job_location,\"Company_Name\":company_name,\"Experience\":experience_job})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbd178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b0f2471",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data asusual\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "5. Now scrape data from this page asusual\n",
    "6. Repeat this until you get data for 100sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76c4c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7393698",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1092b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "30d2ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "20374abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_name=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_name[0:100]:\n",
    "        brand_name.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19679b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_description = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    product_description=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_description[0:100]:\n",
    "        product_description.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e18a4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_detail = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    price_detail=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_detail[0:100]:\n",
    "        price_detail.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e661b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_offer = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    discount_offer=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in discount_offer[0:100]:\n",
    "        discount_offer.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6364d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_name),len(product_description),len(price_detail),len(discount_offer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f8a596bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Others Wrap-around Sunglasses (63)</td>\n",
       "      <td>₹413</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹919</td>\n",
       "      <td>34% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>41% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹629</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Others Over-sized Sunglasses (60)</td>\n",
       "      <td>₹466</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Brand  \\\n",
       "0   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "..                                                ...   \n",
       "75                                          ROYAL SON   \n",
       "76                                           Fastrack   \n",
       "77                                           Fastrack   \n",
       "78                                      VINCENT CHASE   \n",
       "79                                          ROYAL SON   \n",
       "\n",
       "                                              Product  \\\n",
       "0   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "..                                                ...   \n",
       "75                 Others Wrap-around Sunglasses (63)   \n",
       "76         UV Protection Round Sunglasses (Free Size)   \n",
       "77      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "78  UV Protection Cat-eye, Retro Square, Oval, Rou...   \n",
       "79                  Others Over-sized Sunglasses (60)   \n",
       "\n",
       "                                                Price  \\\n",
       "0   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "..                                                ...   \n",
       "75                                               ₹413   \n",
       "76                                               ₹919   \n",
       "77                                               ₹639   \n",
       "78                                               ₹629   \n",
       "79                                               ₹466   \n",
       "\n",
       "                                             Discount  \n",
       "0   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "..                                                ...  \n",
       "75                                            79% off  \n",
       "76                                            34% off  \n",
       "77                                            41% off  \n",
       "78                                            68% off  \n",
       "79                                            81% off  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Brand\":brand_name,\"Product\":product_description,\"Price\":price_detail,\"Discount\":discount_offer})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f7519",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market \n",
    "place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f187ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bf7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be66548",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_one = []\n",
    "start=0\n",
    "end=7\n",
    "for page in range(start,end):\n",
    "    rating_one=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_one[0:100]:\n",
    "        rating_one.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e9bdf23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_sum = []\n",
    "start=0\n",
    "end=7\n",
    "for page in range(start,end):\n",
    "    review_sum=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_sum[0:100]:\n",
    "        review_sum.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "271f2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_review = []\n",
    "start=0\n",
    "end=7\n",
    "for page in range(start,end):\n",
    "    full_review=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_review[0:100]:\n",
    "        full_review.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c7747df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_one),len(review_sum),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ff8430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Best and amazing product.....phone looks so pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>Just got this iphone 11\\nAnd it is most powerf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Amazing camera quality as expected, battery al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It is just awesome mobile for this price from ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Rating  \\\n",
       "0   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "5   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "6   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "7   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "8   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "9   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "10                                                  5   \n",
       "11                                                  5   \n",
       "12                                                  5   \n",
       "13                                                  5   \n",
       "14                                                  4   \n",
       "15                                                  5   \n",
       "16                                                  5   \n",
       "17                                                  4   \n",
       "18                                                  5   \n",
       "19                                                  5   \n",
       "\n",
       "                                               Review  \\\n",
       "0   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "5   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "6   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "7   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "8   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "9   <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "10                                          Fabulous!   \n",
       "11                                     Classy product   \n",
       "12                                  Worth every penny   \n",
       "13                                   Perfect product!   \n",
       "14                                        Good choice   \n",
       "15                                   Perfect product!   \n",
       "16                                 Highly recommended   \n",
       "17                                    Value-for-money   \n",
       "18                                 Highly recommended   \n",
       "19                                   Perfect product!   \n",
       "\n",
       "                                          Full_review  \n",
       "0   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "5   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "6   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "7   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "8   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "9   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "10  This is my first iOS phone. I am very happy wi...  \n",
       "11  Best and amazing product.....phone looks so pr...  \n",
       "12  i11 is worthy to buy, too much happy with the ...  \n",
       "13  It’s a must buy who is looking for an upgrade ...  \n",
       "14  So far it’s been an AMAZING experience coming ...  \n",
       "15  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "16  iphone 11 is a very good phone to buy only if ...  \n",
       "17  Just got this iphone 11\\nAnd it is most powerf...  \n",
       "18  Amazing camera quality as expected, battery al...  \n",
       "19  It is just awesome mobile for this price from ...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Rating\":rating_one,\"Review\":review_sum,\"Full_review\":full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf82d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e8e794c",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27c9c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26b4ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79790d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "758a110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dafe5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_name=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_name[0:100]:\n",
    "        brand_name.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1d50678",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_description = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    product_description=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_description[0:100]:\n",
    "        product_description.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8ffa758",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_detail = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    price_detail=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_detail[0:100]:\n",
    "        price_detail.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "970e3d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 78 80\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_name),len(product_description),len(price_detail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88e0168d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBrand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mbrand_name\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProduct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mproduct_description\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprice_detail\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Brand\":brand_name,\"Product\":product_description,\"Price\":price_detail})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208716f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3d13e14",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ce9afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06f65dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77843a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "designation.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8cbaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"nav-right\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "01f0f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_i7=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/li[10]/span/a/div/label/i\")\n",
    "core_i7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a252371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_na=[]\n",
    "rating_na=[]\n",
    "price_na=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc66119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_na=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_na[0:10]:\n",
    "    title=i.text\n",
    "    title_na.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d3348dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_na=driver.find_elements(By.XPATH,'//span[@class=\"a-size-base\"]')\n",
    "for i in rating_na[0:10]:\n",
    "    rating=i.text\n",
    "    rating_na.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd169c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_na=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_na[0:10]:\n",
    "    price=i.text\n",
    "    price_na.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b15593fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 52 41\n"
     ]
    }
   ],
   "source": [
    "print(len(title_na),len(rating_na),len(price_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a257f3c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [134]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtitle_na\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mrating_na\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprice_na\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Title\":title_na,\"Rating\":rating_na,\"Price\":price_na})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88fd3e",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0985de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7fe23607",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "db65290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quotes=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c14643e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_title = []\n",
    "start=0\n",
    "end=7\n",
    "for page in range(start,end):\n",
    "    quotes_title=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quotes_title[0:1000]:\n",
    "        quotes_title.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//div[@class=\"pager\"]/li[12]/a')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1bca3521",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_title = []\n",
    "start=0\n",
    "end=7\n",
    "for page in range(start,end):\n",
    "    author_title=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_title[0:1000]:\n",
    "        author_title.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//div[@class=\"pager\"]/li[12]/a')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6c2d7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_type = []\n",
    "start=0\n",
    "end=7\n",
    "for page in range(start,end):\n",
    "    quote_type=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in quote_type[0:1000]:\n",
    "        quote_type.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//div[@class=\"pager\"]/li[12]/a')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8e540d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200\n"
     ]
    }
   ],
   "source": [
    "print(len(quotes_title),len(author_title),len(quote_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7181c1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type_of_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes  \\\n",
       "0    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "1    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "2    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "3    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "4    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "..                                                 ...   \n",
       "195  Regret for the things we did can be tempered b...   \n",
       "196  America... just a nation of two hundred millio...   \n",
       "197  For every disciplined effort there is a multip...   \n",
       "198  The spiritual journey is individual, highly pe...   \n",
       "199  The mind is not a vessel to be filled but a fi...   \n",
       "\n",
       "                                                Author  \\\n",
       "0    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "1    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "2    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "3    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "4    <selenium.webdriver.remote.webelement.WebEleme...   \n",
       "..                                                 ...   \n",
       "195                                   Sydney J. Harris   \n",
       "196                                 Hunter S. Thompson   \n",
       "197                                           Jim Rohn   \n",
       "198                                           Ram Dass   \n",
       "199                                           Plutarch   \n",
       "\n",
       "                                         Type_of_quote  \n",
       "0    <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "1    <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "2    <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "3    <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "4    <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "..                                                 ...  \n",
       "195                  Love, Inspirational, Motivational  \n",
       "196                             Gun, Two, Qualms About  \n",
       "197              Inspirational, Greatness, Best Effort  \n",
       "198                             Spiritual, Truth, Yoga  \n",
       "199               Inspirational, Leadership, Education  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Quotes\":quotes_title,\"Author\":author_title,\"Type_of_quote\":quote_type})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b3be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d96a8d8c",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) \n",
    "from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08f9fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e53ef574",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d255491",
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_know=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[9]/a\")\n",
    "gk_know.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d2b4031",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_minister=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "prime_minister.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcb8b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_name=[]\n",
    "prime_age=[]\n",
    "prime_term=[]\n",
    "prime_remark=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cc51495",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_prime=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p')\n",
    "for i in name_prime:\n",
    "    name=i.text\n",
    "    prime_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b597117",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_prime=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[3]/p')\n",
    "for i in age_prime:\n",
    "    age=i.text\n",
    "    prime_age.append(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9ac8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_prime=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[4]/p')\n",
    "for i in term_prime:\n",
    "    term=i.text\n",
    "    prime_term.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8c86d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remark_prime=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[5]/p')\n",
    "for i in remark_prime:\n",
    "    remark=i.text\n",
    "    prime_remark.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "288ac767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 35 18\n"
     ]
    }
   ],
   "source": [
    "print(len(prime_name),len(prime_age),len(prime_term),len(prime_remark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40841d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37e5cdd",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c0d7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\yogendra\\Downloads\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5c9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b8d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_one=driver.find_element(By.XPATH,\"/html/body/div[3]/div[2]/div/div/div[1]\")\n",
    "feature_one.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42df5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_down=driver.find_element(By.XPATH,\"/html/body/div[4]/div[1]/div[3]/ul/li[5]/button\")\n",
    "drop_down.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6b267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_two=driver.find_element(By.XPATH,\"/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a\")\n",
    "feature_two.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c0f98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_expensive=driver.find_element(By.XPATH,\"/html/body/div[3]/div[8]/div[1]/div[1]/div/div/div[8]/div/div[1]/h3/a\")\n",
    "most_expensive.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b5b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_title = []\n",
    "price_tag = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062f7a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_car=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in title_car[0:50]:\n",
    "    car=i.text\n",
    "    car_title.append(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dca48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_price=driver.find_elements(By.XPATH,'//strong[@class=\"trinity-skip-it\"]')\n",
    "for i in tag_price[0:50]:\n",
    "    price=i.text\n",
    "    price_tag.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8622a7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0\n"
     ]
    }
   ],
   "source": [
    "print(len(car_title),len(price_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this i am not able to identify class in the price section..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
